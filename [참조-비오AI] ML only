import os
import glob
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization, Add, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.mixed_precision import set_global_policy
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import cv2 
from scipy.io import loadmat 
set_global_policy('mixed_float16')

try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
except ValueError:
    strategy = tf.distribute.get_strategy()

print("REPLICAS: ", strategy.num_replicas_in_sync)

TRAIN_PATH_1 = 'your_folder_path'
TRAIN_PATH_2 = 'your_folder_path'
TEST_PATH = 'your_folder_path'
EXCEL_FILE_PATH = 'your_folder_path'
WEIGHTS_SAVE_PATH = 'your_folder_path'

excel_data = pd.read_excel(EXCEL_FILE_PATH)
deltaK_mapping = {row['image']: row['deltaK'] for _, row in excel_data.iterrows()}

def load_png_file(file_path, target_shape=(128, 128)):  
    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)  # ml0 채널만 로드
    img_resized = cv2.resize(img, target_shape)
    return (img_resized / 127.5) - 1  

def load_displacement_data_paths(base_path, deltaK_mapping):
    data_paths = []
    deltaK_values = []
    
    for folder_name in os.listdir(base_path):
        folder_path = os.path.join(base_path, folder_name)
        if os.path.isdir(folder_path) and folder_name in deltaK_mapping:
            ml_files = glob.glob(os.path.join(folder_path, 'ml0', '*.png'))
            
            for ml_file in ml_files:
                data_paths.append(ml_file)
                deltaK_values.append(deltaK_mapping[folder_name])
    
    return data_paths, np.array(deltaK_values)
def preprocess_data(data_paths, target_shape=(128, 128)):
    data = []
    for ml_path in data_paths:
        ml_data = load_png_file(ml_path, target_shape)
        data.append(ml_data)
    return np.array(data)[..., np.newaxis]  

def data_augment(image, label):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    image = tf.image.random_brightness(image, max_delta=0.2)
    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)
    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)
    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))
    return image, label

train_paths_1, deltaK_values_1 = load_displacement_data_paths(TRAIN_PATH_1, deltaK_mapping)
train_paths_2, deltaK_values_2 = load_displacement_data_paths(TRAIN_PATH_2, deltaK_mapping)
test_paths, deltaK_values_test = load_displacement_data_paths(TEST_PATH, deltaK_mapping)

all_train_paths = train_paths_1 + train_paths_2
all_deltaK_values = np.concatenate([deltaK_values_1, deltaK_values_2])

x_train = preprocess_data(all_train_paths)
y_train = all_deltaK_values

x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

def residual_block(x, filters, kernel_size=(3, 3), stride=(1, 1), activation='relu'):
    res = Conv2D(filters, kernel_size, strides=stride, padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001), kernel_initializer='he_normal')(x)
    res = BatchNormalization()(res)
    res = Activation(activation)(res)
    
    res = Conv2D(filters, kernel_size, strides=stride, padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001), kernel_initializer='he_normal')(res)
    res = BatchNormalization()(res)
    
    shortcut = Conv2D(filters, (1, 1), strides=stride, padding='same')(x)
    shortcut = BatchNormalization()(shortcut)
    
    x = Add()([shortcut, res])
    return Activation(activation)(x)

def create_resnet_style_model(input_shape):
    inputs = Input(shape=input_shape)
    x = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001), kernel_initializer='he_normal', padding='same')(inputs)
    x = MaxPooling2D((2, 2))(x)
    x = BatchNormalization()(x)
 
    x = residual_block(x, 32)
    x = MaxPooling2D((2, 2))(x)
    
    x = residual_block(x, 128)
    x = MaxPooling2D((2, 2))(x)
    
    x = Flatten()(x)
    x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)
    x = Dropout(0.5)(x)
    outputs = Dense(1, dtype='float32')(x)  # FP32로 출력

    model = Model(inputs, outputs)
    model.compile(optimizer=Adam(learning_rate=3e-4), loss='mse', metrics=['mae'])
    return model

with strategy.scope():
    input_shape = (128, 128, 1) 
    model = create_resnet_style_model(input_shape)

checkpoint_cb = ModelCheckpoint(WEIGHTS_SAVE_PATH, save_best_only=True)
reduce_lr_cb = ReduceLROnPlateau(factor=0.5, patience=5, verbose=1)
early_stopping_cb = EarlyStopping(patience=500, restore_best_weights=True)

history = model.fit(x_train, y_train, 
                    validation_data=(x_val, y_val), 
                    epochs=  ,  
                    batch_size=   * strategy.num_replicas_in_sync
                    callbacks=[checkpoint_cb, reduce_lr_cb, early_stopping_cb])

model.load_weights(WEIGHTS_SAVE_PATH)
x_test = preprocess_data(test_paths)
y_test = deltaK_values_test

test_loss, test_mae = model.evaluate(x_test, y_test)
y_pred = model.predict(x_test)

r2 = r2_score(y_test, y_pred)
print(f"Test Loss: {test_loss}, Test MAE: {test_mae}")
print(f"R^2 Score: {r2}")
epochs = range(1, len(history.history['mae']) + 1)

plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['mae'], label='Training MAE')
plt.plot(epochs, history.history['val_mae'], label='Validation MAE')
plt.title('Mean Absolute Error')
plt.xlabel('Epochs')
plt.ylabel('MAE')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(y_test, y_pred, 'o')
plt.plot([min(y_test), max(y_test)], 
         [min(y_test), max(y_test)], 'r--')
plt.title('R^2 Score')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.text(min(y_test), max(y_test), f'R^2: {r2:.2f}', fontsize=12, verticalalignment='top', horizontalalignment='left')

plt.tight_layout()
plt.show()
